{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why I like Julia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Julia is expressive and understandable\n",
    "- In e.g. Python or R, libraries are mostly written in non-native language. [Here is an example with `pytorch`](https://github.com/pytorch/pytorch).\n",
    "\n",
    "\n",
    "![](img/pytorch.png)\n",
    "\n",
    "\n",
    "- Source code of most Julia libraries is written in **pure Julia**. [Here is an example with Flux.jl](https://github.com/FluxML/Flux.jl), the equivalent of `pytorch` in Julia.\n",
    "\n",
    "  ![](img/flux.png)\n",
    "\n",
    "- This allows to understand exactly what the functions you are using are doing ➡️ this makes you smarter\n",
    "\n",
    "[Here is an example of how is implemented in a dense layer in Julia](https://github.com/FluxML/Flux.jl/blob/0038a60e266d0fca17aa8db99cd6453eb633ee7b/src/layers/basic.jl#L170)\n",
    "\n",
    "```julia\n",
    "function (a::Dense)(x::AbstractVecOrMat)\n",
    "  _size_check(a, x, 1 => size(a.weight, 2))\n",
    "  σ = NNlib.fast_act(a.σ, x)  # replaces tanh => tanh_fast, etc\n",
    "  xT = _match_eltype(a, x)  # fixes Float64 input, etc.\n",
    "  return σ.(a.weight * xT .+ a.bias)\n",
    "end\n",
    "```\n",
    "- This allows you to easily contribute and develop to packages ➡️ this makes you more useful in this world\n",
    "\n",
    "\n",
    "- The language enables you to express ideas in fewer lines of code than in traditional languages such as C++ or Fortran. Perhaps some of the best examples of this are from BeautifulAlgorithms.jl by Robert Moss. Below are some basic examples of loss functions in  Julia and how to program them in a single line of code.\n",
    "\n",
    "![](https://github.com/mossr/BeautifulAlgorithms.jl/raw/master/img/png/loss_functions.png)\n",
    "\n",
    "- The language is emoji friendly! This is how you would define a Lotka Volterra system in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lotka_volterra!(du, u, p, t)\n",
    "    α, β, γ, δ = p\n",
    "    🐰, 🦊 = u\n",
    "    d🐰, d🦊 = du\n",
    "    d🐰 = α * 🐰 - β * 🦊 * 🐰\n",
    "    d🦊 = γ*🐰 * 🦊  - δ * 🦊\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Interactivity\n",
    "\n",
    "Amazing IDE with VS code and inline prompts\n",
    "\n",
    "![](https://code.visualstudio.com/assets/docs/languages/julia/overview.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Package management\n",
    "\n",
    "Julia provides a **built-in package** manager called `Pkg` for **managing packages and environments**. Users can create a new environment and add specific packages to it, and each environment has its own set of dependencies. Julia also allows users to switch between different environments easily.\n",
    "\n",
    "More on that later on!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Execution speed!\n",
    "\n",
    "Let's construct a for loop summation of a random sequence of integers from 1 to 1,000,000,000 (1 billion) that are sampled without replacment.1 Here is the correct answer as a reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase, BenchmarkTools\n",
    "n = 1_000_000_000;\n",
    "function sum_n()\n",
    "    s = 0\n",
    "    for i in 1:n\n",
    "        s = s + i\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "@btime sum_n(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RCall\n",
    "R\"\"\"\n",
    "n = 1000000000\n",
    "sum_n = function(){\n",
    "    s = 0\n",
    "    for (i in n){\n",
    "        s = s + i\n",
    "    }\n",
    "    s\n",
    "}\n",
    "print(system.time(x <- sum_n()))\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support for parallelism\n",
    "\n",
    "\n",
    "```julia\n",
    "Threads.@threads for i in 1:n\n",
    "    myarray[1] = do_stuff(parameters[i])\n",
    "end\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Community well organized\n",
    "\n",
    "There is an active community of users and developers who contribute high-quality packages regularly.\n",
    "\n",
    "- Slack channel\n",
    "- Discourse forum\n",
    "- Youtube tutorials\n",
    "\n",
    "Information available at https://julialang.org/community/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple Dispatch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type PlantSpecies end\n",
    "\n",
    "struct Oak <: PlantSpecies\n",
    "    height::Float64\n",
    "    leaf_area::Float64\n",
    "end\n",
    "\n",
    "struct Maple <: PlantSpecies\n",
    "    height::Float64\n",
    "    leaf_area::Float64\n",
    "end\n",
    "\n",
    "function aboveground_biomass(species::Oak)\n",
    "    return 0.0314 * species.height^2.19 * species.leaf_area^0.91\n",
    "end\n",
    "\n",
    "function aboveground_biomass(species::Maple)\n",
    "    return 0.0215 * species.height^2.42 * species.leaf_area^0.94\n",
    "end\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More interesting use case of multiple dispatch: GPU computing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple dispatch can be useful when it comes to GPU computing because it allows for efficient dispatch of functions to the GPU, which can lead to significant performance gains.\n",
    "\n",
    "In GPU computing, data parallelism is often used to perform computations on large arrays in parallel. This involves splitting the input data into smaller chunks and executing the same code on each chunk concurrently. To take advantage of GPU hardware, computations need to be executed on the GPU in parallel.\n",
    "\n",
    "Julia's multiple dispatch mechanism allows functions to be specialized for different types of data and to dispatch the computation to the GPU when appropriate. This is achieved through Julia's `GPUArrays` package, which provides a GPU-backed array type that can be used in place of regular Julia arrays.\n",
    "\n",
    "When a function is called on a `GPUArray`, Julia's multiple dispatch mechanism can determine if a GPU version of the function is available, and if so, dispatch the computation to the GPU. This allows computations to be executed in parallel on the GPU, which can lead to significant performance gains over executing the same computation on the CPU.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "```julia\n",
    "using CUDA\n",
    "\n",
    "function add_matrices(a::AbstractArray, b::AbstractArray)\n",
    "    return a + b\n",
    "end\n",
    "\n",
    "# generate CPU arrays\n",
    "a = rand(1000, 1000)\n",
    "b = rand(1000, 1000)\n",
    "\n",
    "# call the function on CPU arrays\n",
    "c = add_matrices(a, b)\n",
    "\n",
    "# generate GPU arrays\n",
    "a_gpu = CUDA.rand(1000, 1000)\n",
    "b_gpu = CUDA.rand(1000, 1000)\n",
    "\n",
    "# call the function on GPU arrays\n",
    "c_gpu = add_matrices(a_gpu, b_gpu)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "In this example, we define a function `add_matrices` that adds two arrays together. When called with `a_gpu` and `b_gpu`, Julia's multiple dispatch mechanism recognizes that a GPU version of the function is available and dispatches the computation to the GPU.\n",
    "\n",
    "The resulting `c_gpu` array contains the result of the computation, which can be copied back to the CPU using the `Array` function.\n",
    "\n",
    "In summary, multiple dispatch in Julia can be useful when it comes to GPU computing because it allows functions to be specialized for different types of data and to dispatch computations to the GPU when appropriate. This can lead to significant performance gains, especially when working with large arrays."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia Integrates well with existing code\n",
    "\n",
    "Calling C, Fortran, Python, and other libraries from  Julia is easy thanks to its first class support for interoperability.\n",
    "\n",
    "More on that later on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Productivity\n",
    "\n",
    "- Code can be made very generic\n",
    "  - For instance, code can be very effortlessly used for GPU computing\n",
    "- Research script can be easily transformed into **packages**, directly available to the community"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Composability of libraries and scientific ML\n",
    "### Julia is an automatic differentiation pervasive language [(Innes et al., 2019)](http://arxiv.org/abs/1907.07587)\n",
    "\n",
    "### The [SciML](https://sciml.ai) ecosystem\n",
    "\n",
    "SciML is a composable open source software for scientific machine learning with differentiable programming.\n",
    "   -  Read [this very cool paper](https://arxiv.org/abs/2001.04385) introducing the [SciML software ecosystem]\n",
    "   - [Example using Deep Learning libraries in combination with ODE solvers](ode_solvers_with_DL.jl)\n",
    "\n",
    "```julia\n",
    "function lotka_volterra(u, p, t)\n",
    "    weights_nn, α, δ = p\n",
    "    🐰, 🦊 = u\n",
    "\n",
    "    nn_res = neuralnet(🦊, 🐰, weights_nn)\n",
    "\n",
    "    d🐰 = α * 🐰 - nn_res[1]\n",
    "    d🦊 = nn_res[2]  - δ * 🦊\n",
    "\n",
    "    return [d🐰, d🦊]\n",
    "end\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian inference framework with deep learning\n",
    "\n",
    "[Here is another cool example](https://turinglang.org/v0.24/tutorials/03-bayesian-neural-network/) of composability between [`Turing.jl`](https://turinglang.org/v0.24/) and `Flux.jl`\n",
    "\n",
    "![](https://turinglang.org/v0.24/tutorials/figures/03_bayesian-neural-network_9_1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few packages that I have developed\n",
    "\n",
    "### [EvoId.jl](https://github.com/vboussange/EvoId.jl)\n",
    "Evolutionary Individual based modelling, mathematically grounded. A user friendly package aimed at simulating the evolutionary dynamics of a population structured over a complex spatio-evolutionary structures.\n",
    "\n",
    "### [HighDimPDE.jl](https://github.com/SciML/HighDimPDE.jl)\n",
    "Solver for **highly dimensional, non-local, nonlinear PDEs**. It is integrated within the SciML ecosystem (see below). Try it out! &#128515; If you want to learn more about the algorithms implemented, check out my [research interests]({{site.url}}/research/#developping-numerical-schemes-for-solving-high-dimensional-non-local-nonlinear-pdes).\n",
    "\n",
    "### [PiecewiseInference.jl](https://github.com/vboussange/PiecewiseInference.jl)\n",
    "Suite for parameter inference and model selection with dynamical models characterised by complex dynamics.\n",
    "\n",
    "### [ParametricModels.jl](https://github.com/vboussange/ParametricModels.jl)\n",
    "Utilities for parametric and composite differential equation models.\n",
    "\n",
    "### [EcoEvoModelZoo.jl](https://github.com/vboussange/EcoEvoModelZoo.jl)\n",
    "A zoo of eco-evolutionary models with high fitness.\n",
    "\n",
    "### [SciML](https://github.com/SciML/)\n",
    "I am a member of the **SciML** organisation, an open source ecosystem for Scientific Machine Learning in the Julia programming language. On top of being the main author of **HighDimPDE.jl**, I actively participate in the development of other packages such as [DiffEqFlux.jl](https://github.com/SciML/DiffEqFlux.jl), a library to train differential equations with data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
