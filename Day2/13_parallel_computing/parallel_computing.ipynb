{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel and Distributed Computing\n",
    "\n",
    "**Multithreading** refers to the ability of a processor to execute multiple threads concurrently, where each thread runs a process. **Multiprocessing** refers to the ability of a system to run multiple processors concurrently, where each processor can run one or more threads.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*hZ3guTdmDMXevFiT5Z3VrA.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading\n",
    "Multi-threading is a programming technique that allows **multiple threads** of execution to run concurrently within a single process. Julia provides built-in support for multi-threading, making it easy to write concurrent code. To use multi-threading in Julia, you can use the Threads standard library.\n",
    "\n",
    "The number of execution threads is controlled either by using the `-t`/`--threads` command line argument \n",
    "\n",
    "```shell\n",
    "julia --threads 10 my_script.jl\n",
    "```\n",
    "\n",
    "or by using the `JULIA_NUM_THREADS` environment variable. This can also be changed in VSCode setting. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When both `JULIA_NUM_THREADS` and `-t`/`--threads` are specified, then `-t`/`--threads` takes precedence.\n",
    "\n",
    "The number of threads can either be specified as an integer (`--threads=4`) or as auto (`--threads=auto`), where auto sets the number of threads to the number of local CPU threads.\n",
    "\n",
    "To check the number of threads available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Multithreading in Julia is **super easy**: just put `Threads.@threads` in front of the loop you want to parrallelize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 5.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "a = zeros(10)\n",
    "\n",
    "Threads.@threads for i = 1:10\n",
    "    a[i] = Threads.threadid()\n",
    "end\n",
    "println(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be careful with race condition!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Float64[]\n",
    "Threads.@threads for i in 1:100\n",
    "    x = i^2\n",
    "    push!(a, x)\n",
    "end\n",
    "println(length(a)) # !== 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `lock`\n",
    "\n",
    "The `lock` function can be used to prevent race condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "    lk = ReentrantLock()\n",
    "    Threads.@threads for i in 1:100\n",
    "        x = i^2\n",
    "        lock(lk) do\n",
    "            push!(a, x)\n",
    "        end\n",
    "    end\n",
    "    println(length(a)) # ==1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👍 How I use multithreading in my simulations\n",
    "\n",
    "I typically have an expensive function that I want to call multiple times with different arguments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function simul(noise, batch_size)\n",
    "    # do something with noise and batch_size\n",
    "    sleep(1)\n",
    "    return randn()\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`simul` does some simulation based on the `noise` and `batch_size` parameters, then returns the simulation result.\n",
    "\n",
    "I want to loops through all combinations of the arguments proposed. Let's do so by creating a dictionary `pars` for each combination of arguments, and adding it to an array `pars_arr`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_arr = Dict[]\n",
    "\n",
    "noises = [0.1, 0.2, 0.3]\n",
    "batch_sizes = [1000, 2000, 3000]\n",
    "\n",
    "for noise in noises, batch_size in batch_sizes\n",
    "    pars = Dict()\n",
    "    pars[\"noise\"] = noise\n",
    "    pars[\"batch_size\"] = batch_size\n",
    "    push!(pars_arr, pars)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create a `DataFrame` to store the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = DataFrame(\"Result\" => [],\n",
    "                    \"noise\" => [],\n",
    "                    \"batch_size\" => [])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how I would run the simulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ProgressMeter\n",
    "progr = Progress(length(pars_arr), showspeed = true, barlen = 10)\n",
    "\n",
    "loc = Threads.ReentrantLock()\n",
    "\n",
    "Threads.@threads for k in 1:length(pars_arr)\n",
    "    p = pars_arr[k]\n",
    "    noise = p[\"noise\"]\n",
    "    batch_size = p[\"batch_size\"]\n",
    "    try\n",
    "        out = simul(noise, batch_size)\n",
    "        lock(loc) do\n",
    "            push!(df_results, (out, noise, batch_size));\n",
    "        end\n",
    "    catch e\n",
    "        println(\"problem with p = $(pars_arr[k])\")\n",
    "        println(e)\n",
    "    end\n",
    "    next!(progr)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like using `ProgressMeter`, to get a sense of where my computation is at."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Atomic operations\n",
    "Note that you can also perform something called atomic operations, see the [dedicated section](https://docs.julialang.org/en/v1/manual/multi-threading/#Atomic-Operations) in Julia documentation. Atomic operations are similar to what you could do with `lock`, although they may be faster but more limited in what you could do.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Multi-processing\n",
    "\n",
    "### `Distributed`\n",
    "Julia has also a built-in library for distributed parallel computing, called `Distributed`. Although it is generally more difficult to deploy than mulitthreading, it may be useful in certain occasions.  Distributed computing is useful when you have a lot of work that cannot be split among multiple threads and needs to be distributed across multiple machines.\n",
    "\n",
    "Monte Carlo simulations is another good use-case with distributed computing may be useful.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`julia -p 4` provides `4` worker processes on the local machine. Alternatively, within Julia you can add workers by \n",
    "```julia\n",
    "using Distributed\n",
    "addprocs(4)  # add 4 worker processes\n",
    "```\n",
    "\n",
    "The most straightforward way of performing distributed computing is using  `pmap`. A good tutorial on how to use `pmap` can be found [here](https://github.com/Arpeggeo/julia-distributed-computing).\n",
    "\n",
    "Note that [ClusterManagers.jl](https://github.com/JuliaParallel/ClusterManagers.jl) may be useful for distributed computing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### `MPI.jl`\n",
    "There exists an MPI (Message Passing Interface) interface for the Julia language, provided by the `MPI.jl` package. MPI is a low-level communication protocol that enables message passing between processes running on different nodes in a distributed system. It may be a better choice due to its interoperability, customization options, performance, and scalability on large-scale systems. If you never heard of it, then forget about it!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## GPU computing\n",
    "\n",
    "Multiple dispatch allows your code to be executed on GPUS! Here is how.\n",
    "\n",
    "Assume\n",
    "```julia\n",
    "\n",
    "function myfun(a::AbstractArray, b::AbstractArray)\n",
    "    return sum(a.^2 .* b)\n",
    "end\n",
    "\n",
    "# generate CPU arrays\n",
    "a = rand(Float32, 1000, 1000)\n",
    "b = rand(Float32, 1000, 1000)\n",
    "\n",
    "using BenchmarkTools\n",
    "@btime myfun(a, b) # 820.959 μs (3 allocations: 7.63 MiB)\n",
    "```\n",
    "\n",
    "### GPU programming on MacOS\n",
    "```julia\n",
    "using Metal\n",
    "a_gpu = MtlArray(a)\n",
    "b_gpu = MtlArray(b)\n",
    "\n",
    "@btime myfun(a_gpu, b_gpu)\n",
    "```\n",
    "\n",
    "### GPU programming with CUDA\n",
    "```julia\n",
    "using CUDA\n",
    "\n",
    "if CUDA.functional()\n",
    "    a = CUDA.rand(1000, 1000)\n",
    "    b = CUDA.rand(1000, 1000)\n",
    "    @btime myfun(a, b)\n",
    "end\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional resources\n",
    "- [Discourse category Julia at scale](https://discourse.julialang.org/c/domain/parallel/34)\n",
    "- [Further explanations on Multithreading vs Multiprocessing computing](https://towardsdatascience.com/multithreading-and-multiprocessing-in-10-minutes-20d9b3c6a867)\n",
    "- [Julia multi threading](https://docs.julialang.org/en/v1/manual/multi-threading/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
