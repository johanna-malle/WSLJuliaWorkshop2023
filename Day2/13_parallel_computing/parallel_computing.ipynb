{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel and Distributed Computing\n",
    "\n",
    "**Multithreading** refers to the ability of a processor to execute multiple threads concurrently, where each thread runs a process. **Multiprocessing** refers to the ability of a system to run multiple processors concurrently, where each processor can run one or more threads.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*hZ3guTdmDMXevFiT5Z3VrA.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading\n",
    "Multi-threading is a programming technique that allows **multiple threads** of execution to run concurrently within a single process. Julia provides built-in support for multi-threading, making it easy to write concurrent code. To use multi-threading in Julia, you can use the Threads standard library.\n",
    "\n",
    "The number of execution threads is controlled either by using the `-t`/`--threads` command line argument \n",
    "\n",
    "```shell\n",
    "julia --threads 10 my_script.jl\n",
    "```\n",
    "\n",
    "or by using the `JULIA_NUM_THREADS` environment variable. This can also be changed in VSCode setting. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When both `JULIA_NUM_THREADS` and `-t`/`--threads` are specified, then `-t`/`--threads` takes precedence.\n",
    "\n",
    "The number of threads can either be specified as an integer (`--threads=4`) or as auto (`--threads=auto`), where auto sets the number of threads to the number of local CPU threads.\n",
    "\n",
    "To check the number of threads available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Multithreading in Julia is **super easy**: just put `Threads.@threads` in front of the loop you want to parrallelize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.0, 5.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "a = zeros(10)\n",
    "\n",
    "Threads.@threads for i = 1:10\n",
    "    a[i] = Threads.threadid()\n",
    "end\n",
    "println(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be careful with race condition!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Float64[]\n",
    "Threads.@threads for i in 1:100\n",
    "    x = i^2\n",
    "    push!(a, x)\n",
    "end\n",
    "println(length(a)) # !== 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `lock`\n",
    "\n",
    "The `lock` function can be used to prevent race condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "lk = ReentrantLock()\n",
    "Threads.@threads for i in 1:100\n",
    "    x = i^2\n",
    "    lock(lk) do\n",
    "        push!(a, x)\n",
    "    end\n",
    "end\n",
    "println(length(a)) # ==1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overhead\n",
    "There's a performance benefit to parallelization, but the overhead for starting threads may be an overkill. For multithreading to be worth, you need a reasonably large amount of \"real work\"; this would demonstrate scaling that is closer to linear in the number of cores. Conversely, with small works, the parallel version might be slower than the serial version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2^30\n",
    "x = fill(1.0f0, N)  # a vector filled with 1.0 (Float32)\n",
    "y = fill(2.0f0, N);  # a vector filled with 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  437.580 ms (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "function sequential_add!(y, x)\n",
    "    for i in eachindex(y, x)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "@btime sequential_add!($y, $x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  437.179 ms (8 allocations: 592 bytes)\n"
     ]
    }
   ],
   "source": [
    "function parallel_add!(y, x)\n",
    "    Threads.@threads for i in eachindex(y, x)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "@btime parallel_add!($y, $x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üëç How I use multithreading in my simulations\n",
    "\n",
    "I typically have an expensive function that I want to call multiple times with different arguments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simul (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function simul(noise, batch_size)\n",
    "    # do something with noise and batch_size\n",
    "    sleep(1)\n",
    "    return randn()\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`simul` does some simulation based on the `noise` and `batch_size` parameters, then returns the simulation result.\n",
    "\n",
    "I want to loops through all combinations of the arguments proposed. Let's do so by creating a dictionary `pars` for each combination of arguments, and adding it to an array `pars_arr`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_arr = Dict[]\n",
    "\n",
    "noises = [0.1, 0.2, 0.3]\n",
    "batch_sizes = [1000, 2000, 3000]\n",
    "\n",
    "for noise in noises, batch_size in batch_sizes\n",
    "    pars = Dict()\n",
    "    pars[\"noise\"] = noise\n",
    "    pars[\"batch_size\"] = batch_size\n",
    "    push!(pars_arr, pars)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create a `DataFrame` to store the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>0√ó3 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Result</th><th style = \"text-align: left;\">noise</th><th style = \"text-align: left;\">batch_size</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Any\" style = \"text-align: left;\">Any</th></tr></thead><tbody></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& Result & noise & batch\\_size\\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any\\\\\n",
       "\t\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m0√ó3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m‚îÇ\u001b[1m Result \u001b[0m\u001b[1m noise \u001b[0m\u001b[1m batch_size \u001b[0m\n",
       "     ‚îÇ\u001b[90m Any    \u001b[0m\u001b[90m Any   \u001b[0m\u001b[90m Any        \u001b[0m\n",
       "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using DataFrames\n",
    "df_results = DataFrame(\"Result\" => [],\n",
    "                    \"noise\" => [],\n",
    "                    \"batch_size\" => [])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how I would run the simulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[32mProgress:  22%|‚ñà‚ñà‚ñé       |  ETA: 0:00:06 ( 0.81  s/it)\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[32mProgress:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   |  ETA: 0:00:01 ( 0.47  s/it)\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\u001b[32mProgress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:02 ( 0.31  s/it)\u001b[39m\u001b[K"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "using ProgressMeter\n",
    "progr = Progress(length(pars_arr), showspeed = true, barlen = 10)\n",
    "\n",
    "loc = Threads.ReentrantLock()\n",
    "\n",
    "Threads.@threads for k in 1:length(pars_arr)\n",
    "    p = pars_arr[k]\n",
    "    noise = p[\"noise\"]\n",
    "    batch_size = p[\"batch_size\"]\n",
    "    try\n",
    "        out = simul(noise, batch_size)\n",
    "        lock(loc) do\n",
    "            push!(df_results, (out, noise, batch_size));\n",
    "        end\n",
    "    catch e\n",
    "        println(\"problem with p = $(pars_arr[k])\")\n",
    "        println(e)\n",
    "    end\n",
    "    next!(progr)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like using `ProgressMeter`, to get a sense of where my computation is at."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Atomic operations\n",
    "Note that you can also perform something called atomic operations, see the [dedicated section](https://docs.julialang.org/en/v1/manual/multi-threading/#Atomic-Operations) in Julia documentation. Atomic operations are similar to what you could do with `lock`, although they may be faster but more limited in what you could do.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Multi-processing\n",
    "\n",
    "### `Distributed`\n",
    "Julia has also a built-in library for distributed parallel computing, called `Distributed`. Although it is generally more difficult to deploy than mulitthreading, it may be useful in certain occasions.  Distributed computing is useful when you have a lot of work that cannot be split among multiple threads and needs to be distributed across multiple machines.\n",
    "\n",
    "Monte Carlo simulations is another good use-case with distributed computing may be useful.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`julia -p 4` provides `4` worker processes on the local machine. Alternatively, within Julia you can add workers by \n",
    "```julia\n",
    "using Distributed\n",
    "addprocs(4)  # add 4 worker processes\n",
    "```\n",
    "\n",
    "The most straightforward way of performing distributed computing is using  `pmap`. A good tutorial on how to use `pmap` can be found [here](https://github.com/Arpeggeo/julia-distributed-computing).\n",
    "\n",
    "Note that [ClusterManagers.jl](https://github.com/JuliaParallel/ClusterManagers.jl) may be useful for distributed computing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### `MPI.jl`\n",
    "There exists an MPI (Message Passing Interface) interface for the Julia language, provided by the `MPI.jl` package. MPI is a low-level communication protocol that enables message passing between processes running on different nodes in a distributed system. It may be a better choice due to its interoperability, customization options, performance, and scalability on large-scale systems. If you never heard of it, then forget about it!\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## GPU computing\n",
    "\n",
    "Multiple dispatch allows your code to be executed on GPUS! Here is how.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### GPU programming with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  456.008 Œºs (3 allocations: 3.81 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "166483.64f0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "function myfun(a::AbstractArray, b::AbstractArray)\n",
    "    return sum(a.^2 .* b)\n",
    "end\n",
    "\n",
    "# generate CPU arrays\n",
    "a = rand(Float32, 1000, 1000)\n",
    "b = rand(Float32, 1000, 1000)\n",
    "\n",
    "using BenchmarkTools\n",
    "@btime myfun(a, b) # 820.959 Œºs (3 allocations: 7.63 MiB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuDevice(0)\n",
      "CuDevice(1)\n",
      "CuDevice(2)\n",
      "CuDevice(3)\n",
      "CuDevice(4)\n",
      "CuDevice(5)\n",
      "CuDevice(6)\n",
      "CuDevice(7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CuDevice(1): NVIDIA TITAN RTX"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using CUDA\n",
    "\n",
    "@assert CUDA.functional()\n",
    "\n",
    "for d in devices()\n",
    "    println(d)\n",
    "end\n",
    "CUDA.device!(1)\n",
    "CUDA.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000√ó1000 CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}:\n",
       " 0.140214   0.622038   0.73573    ‚Ä¶  0.836653   0.640832   0.088709\n",
       " 0.702914   0.142996   0.282872      0.312544   0.551903   0.778418\n",
       " 0.347167   0.422628   0.214782      0.556982   0.21898    0.436132\n",
       " 0.109869   0.405116   0.175415      0.295749   0.558965   0.227327\n",
       " 0.696447   0.966963   0.0538881     0.557063   0.807533   0.415223\n",
       " 0.63939    0.679551   0.722373   ‚Ä¶  0.0821103  0.28504    0.817443\n",
       " 0.435309   0.0315925  0.0783469     0.223421   0.196664   0.371542\n",
       " 0.705055   0.219103   0.749981      0.759564   0.774275   0.593102\n",
       " 0.0855225  0.676072   0.0670949     0.670792   0.723975   0.508414\n",
       " 0.973308   0.535222   0.0419881     0.929245   0.713791   0.79461\n",
       " ‚ãÆ                                ‚ã±                        \n",
       " 0.249762   0.0335487  0.240396      0.798747   0.161045   0.826653\n",
       " 0.711381   0.793769   0.178583      0.976543   0.946686   0.193337\n",
       " 0.166499   0.0293248  0.885914      0.712727   0.865431   0.72912\n",
       " 0.299901   0.656972   0.490112      0.355389   0.588482   0.273179\n",
       " 0.214667   0.0246     0.355524   ‚Ä¶  0.0344379  0.761051   0.970077\n",
       " 0.399115   0.899991   0.648519      0.486175   0.577976   0.0240522\n",
       " 0.0692634  0.384197   0.276452      0.867125   0.130875   0.30818\n",
       " 0.618672   0.18132    0.223234      0.8422     0.264108   0.746487\n",
       " 0.0532538  0.149547   0.911722      0.66814    0.0435654  0.186378"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = CUDA.rand(1000, 1000)\n",
    "b = CUDA.rand(1000, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  60.250 Œºs (125 allocations: 6.86 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "166715.84f0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@btime myfun(a, b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### GPU programming on MacOS\n",
    "```julia\n",
    "using Metal\n",
    "a_gpu = MtlArray(a)\n",
    "b_gpu = MtlArray(b)\n",
    "\n",
    "@btime myfun(a_gpu, b_gpu)\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional resources\n",
    "- [Discourse category Julia at scale](https://discourse.julialang.org/c/domain/parallel/34)\n",
    "- [Further explanations on Multithreading vs Multiprocessing computing](https://towardsdatascience.com/multithreading-and-multiprocessing-in-10-minutes-20d9b3c6a867)\n",
    "- [Julia multi threading](https://docs.julialang.org/en/v1/manual/multi-threading/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
